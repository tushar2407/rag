{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (0.0.2)\n",
      "Requirement already satisfied: langchain_community in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (0.0.38)\n",
      "Requirement already satisfied: tiktoken in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (0.7.0)\n",
      "Requirement already satisfied: langchain-openai in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (0.1.7)\n",
      "Requirement already satisfied: langchainhub in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (0.1.15)\n",
      "Requirement already satisfied: chromadb in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: langchain in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (0.1.20)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchain_community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchain_community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchain_community) (0.6.6)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchain_community) (0.1.52)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchain_community) (0.1.58)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchain_community) (8.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchain-openai) (1.30.1)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchainhub) (2.31.0.20240406)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (2.7.1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (0.111.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.29.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (4.11.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (1.63.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (4.1.3)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (0.12.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (29.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from chromadb) (3.10.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (0.0.3)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (0.0.9)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (2.1.1)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.29.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain_community) (1.33)\n",
      "Requirement already satisfied: coloredlogs in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.2.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb) (0.23.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb) (2.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from httpx>=0.23.0->fastapi>=0.95.2->chromadb) (1.0.5)\n",
      "Requirement already satisfied: filelock in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain_community) (2.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install bs4 langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY', '')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing\n",
    "\n",
    "# Load documents\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VectorStores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_hub_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\" , temperature=0.5)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt_hub_rag\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is the process of breaking down a complex task into smaller, more manageable sub-tasks. This approach helps in organizing and prioritizing tasks to achieve the overall goal efficiently. Task decomposition is commonly used in project management and software development.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='Answer the question based only on the following context:\\n{context}\\n\\n\\nQuestion: {question}\\n'))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Task Decomposition refers to breaking down a complex task into smaller, more manageable sub-tasks or components.', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 60, 'total_tokens': 81}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-16fd03c7-a712-495b-964c-843e08c1f997-0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain.invoke({\"context\": docs, \"question\": \"What is Task Decomposition?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Translation -- Multi-Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five different versions of the given user question to retrieve relevant documents from a vector database. By generating multiple perspectives on the user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search.\n",
    "Provide these alternative questions separated by newlines. Original question: {question}\n",
    "\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_queries = (\n",
    "    prompt_perspectives\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tush/miniconda3/envs/ds/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    flatten_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    unique_docs = list(set(flatten_docs))\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "question = \"What is Task Decomposition for LLM agents?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM agents involves breaking down large tasks into smaller, manageable subgoals.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "template = \"\"\"Answer the following question based on this context: \n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "final_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Translation -- RAG Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to {question}\\n\n",
    "Output (4 queries):\"\"\"\n",
    "\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    fused_scores = {}\n",
    "\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "\n",
    "            fused_scores[doc_str] += 1/(rank+k)\n",
    "\n",
    "    return [\n",
    "        (loads(doc), score) \n",
    "        for doc, score in sorted(fused_scores.items(), key = lambda x: x[1], reverse=True)\n",
    "    ]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is Task Decomposition for LLM agents?\"\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM agents involves breaking down large tasks into smaller, manageable subgoals using simple prompting such as \"Steps for XYZ.\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Translation -- Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate multiple search queries related to {question}\\n\n",
    "Output (3 queries):\n",
    "\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\" , temperature=0.5)\n",
    "\n",
    "generate_queries_decomposition = (\n",
    "    prompt_decomposition\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "question = \"What are the main components of an LLM-powered autonomous agent system?\"\n",
    "questions = generate_queries_decomposition.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. What is LLM technology and how does it work in autonomous agent systems?',\n",
       " '2. What are the specific components that make up an LLM-powered autonomous agent system?',\n",
       " '3. How do the main components of an LLM-powered autonomous agent system interact with each other to enable autonomous functionality?']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Here is the question you need to answer: \n",
    "\n",
    "\\n -- \\n   {question} \\n -- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n -- \\n   {q_a_pairs} \\n -- \\n\n",
    "\n",
    "Here is additional context relevant to the question:\n",
    "\n",
    "\\n -- \\n   {context} \\n -- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_qa_pair(question, answer):\n",
    "    return f\"Question: {question}\\nAnswer: {answer}\\n\\n\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\" , temperature=0.5)\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": itemgetter(\"question\") | retriever, \n",
    "         \"question\": itemgetter(\"question\"),\n",
    "         \"q_a_pairs\": itemgetter(\"q_a_pairs\")}\n",
    "        | decomposition_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = rag_chain.invoke({\"question\": q, \"q_a_pairs\": q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q, answer)\n",
    "    q_a_pairs += \"\\n--\\n\" + q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The main components of an LLM-powered autonomous agent system interact with each other in a cohesive manner to enable autonomous functionality. \\n\\n1. Large Language Models (LLMs) interact with Natural Language Processing (NLP) capabilities to understand and generate human language effectively. This interaction allows the autonomous agent to process and respond to natural language inputs from users.\\n\\n2. The communication interface facilitates the interaction between the autonomous agent and users through natural language commands and responses. This interface serves as the bridge for communication between the agent and the human user.\\n\\n3. Decision-making algorithms utilize the input from LLMs and NLP capabilities to make informed choices based on the language inputs received. This interaction enables the autonomous agent to make intelligent decisions autonomously.\\n\\n4. Task-specific modules work in conjunction with LLMs, NLP capabilities, and decision-making algorithms to perform various functions or tasks based on the natural language commands received. These modules enable the autonomous agent to execute specific actions or tasks based on the user's requests.\\n\\nOverall, the seamless interaction between these main components - LLMs, NLP capabilities, communication interface, decision-making algorithms, and task-specific modules - enables the LLM-powered autonomous agent system to operate autonomously and intelligently in various tasks and scenarios.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Translation -- Step Back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
